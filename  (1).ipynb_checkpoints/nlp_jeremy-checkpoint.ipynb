{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaf1f1-825f-4f51-8b46-dda9d46ad5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import html\n",
    "import requests\n",
    "import tarfile\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83755bb2-fd5c-4725-9243-9475cc1cea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid = \"23193287\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610af05-07a3-4052-ab2b-1b0aad8349bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pmc_from_pmid(pmid):\n",
    "    \"\"\" Using the NCBI 'PMC ID Converter' API, Get a PMCID\n",
    "    \n",
    "        @docs https://www.ncbi.nlm.nih.gov/pmc/tools/id-converter-api/\n",
    "        @notes\n",
    "            To search for multiple pmids you can do this in one call:\n",
    "            https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=1,2,3\n",
    "            \n",
    "            But you need to join the values.  Thankfully Python makes it easy:\n",
    "            e.g. \n",
    "                pmid_array = [\"1\",\"2\",\"3\"]\n",
    "                pmid_string = pmid_array.join(\",\") # results in \"1,2,3\"\n",
    "                url = f\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids={pmid_string}\"\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids={pmid}\")\n",
    "    xml = ET.fromstring(response.text)\n",
    "    return xml.find('record').attrib.get(\"pmcid\",None)\n",
    "\n",
    "def get_ftp_from_pmcid(pmcid):\n",
    "    \"\"\" Using the NCBI Open Access (OA) API, Get the ftp location for the PCM data\n",
    "        @docs https://www.ncbi.nlm.nih.gov/pmc/tools/oa-service/\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"https://www.ncbi.nlm.nih.gov/pmc/utils/oa/oa.fcgi?id={pmcid}\")\n",
    "    xml = ET.fromstring(response.text)\n",
    "    \n",
    "    for c in xml.find(\"records\").find('record').findall('link'):\n",
    "        if fmt := c.attrib.get('format',None):\n",
    "            if fmt.lower() == 'tgz':\n",
    "                return c.attrib.get('href')\n",
    "    return None\n",
    "\n",
    "def get_tar_gz_from_ftpid(ftpid, local_file_path):\n",
    "    \"\"\" Using the NCBI FTP, Download .tar.gz data from the FTP\n",
    "        @notes\n",
    "            * This function simply downloads the data to your computer, opening the file\n",
    "            using python would be the next step.  \n",
    "    \"\"\"\n",
    "    # `requests` can't handle FTP requests but Python has a standard library to help us out\n",
    "    response = urllib.request.urlopen(ftpid)\n",
    "    with open(local_file_path, \"wb\") as fw:\n",
    "        shutil.copyfileobj(response,fw)\n",
    "        \n",
    "    \n",
    "def get_xml_from_ftpid(ftpid):\n",
    "    \"\"\" Using the NCBI FTP, Get the XML data (As a string) from the FTP\n",
    "        @notes\n",
    "            * NCBI's FTP returns .tar.gz files\n",
    "            * NCBI's .tar.gz files contain X files, the one we want ends with .nxml\n",
    "            * This snippet uses some lesser known features of Python to avoid downloading\n",
    "            .tar.gz locally.  Everything happens in-memory.\n",
    "    \"\"\"\n",
    "\n",
    "    # `requests` can't handle FTP requests but Python has a standard library to help us out\n",
    "    response = urllib.request.urlopen(ftpid)\n",
    "    \n",
    "    # Here's a fun hack.  Instead of downloading the .tar.gaz file locally we \"download\" it\n",
    "    # in to memory.  \n",
    "    memfile = BytesIO(response.read())\n",
    "\n",
    "    # Next we need to use Python's tar library to open the file (still in memory) and extract\n",
    "    # the xml content.\n",
    "    with tarfile.open(fileobj=memfile, mode=\"r:gz\",encoding='utf-8') as tar_file:\n",
    "        for member in tar_file.getmembers():\n",
    "            \n",
    "            # Uncomment this line to print the file names in the .tar.gz file\n",
    "            #print(member.name)\n",
    "            \n",
    "            if \".nxml\" in member.name:\n",
    "                f = tar_file.extractfile(member)\n",
    "                contents = f.read()\n",
    "                return contents\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cb58a-2496-4731-9807-777fb5a541ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = get_pmc_from_pmid(pmid)\n",
    "pmcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94ad92-b290-4820-b9a5-de38fdfad48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftpid = get_ftp_from_pmcid(pmcid)\n",
    "ftpid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c1446a-94cf-4842-8bed-7771ac5f5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_content = get_xml_from_ftpid(ftpid)\n",
    "xml_content[:500] #only print first 500 characters to avoid making a mess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7f775-76b7-48fe-81df-0f3eff6b2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c699adf-ce5f-4be2-8e0b-861c0d7f28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spacy_matches(doc,nlp,matches,padding_start=5,padding_end=5):\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start-padding_start:end+padding_end]  # The matched span\n",
    "        print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44064eb9-3358-46e0-b889-d4a06c09db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the raw XML data we do a few things first.\n",
    "\n",
    "# 1:  Convert from a byte-string to a unicode string.  \n",
    "xml_content_as_string = xml_content.decode('utf-8')\n",
    "\n",
    "# 2:  Replace HTML-escaped characters like &#x02018; with ' \n",
    "# (https://www.quackit.com/character_sets/unicode/general_punctuation_unicode_character_codes.cfm)\n",
    "xml_content_as_string = html.unescape(xml_content_as_string)\n",
    "\n",
    "# To use spacy we convert our string to a spacy document using the \"en_core_web_sm\"\n",
    "# corpus of english words and punctuation.\n",
    "doc = nlp(xml_content_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1724f-e0c3-4dbb-971c-5c933bd47e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/rule-based-matching\n",
    "patterns = [\n",
    "    [{\"LOWER\": \"accession\"}],\n",
    "]\n",
    "\n",
    "# find any instance of the word 'accession'.\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Accession\", patterns)\n",
    "matches = matcher(doc)\n",
    "print_spacy_matches(doc,nlp,matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66e743-5006-4b2f-bf2b-d812ae9dc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patterns = [\n",
    "    [{\"LOWER\": \"wgs\"},{\"LOWER\": \"accession\"},{\"LOWER\": \"number\"}],\n",
    "    # [{\"LOWER\": \"pdb\"}],\n",
    "    # [{\"LOWER\": \"genbank\"}],\n",
    "]\n",
    "\n",
    "# find any instance of the words 'wgs access number'\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Accessions\", patterns)\n",
    "matches = matcher(doc)\n",
    "\n",
    "print_spacy_matches(doc,nlp,matches,padding_start=0,padding_end=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88aa40e-7b36-4377-a948-55052a052894",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    [{\"TEXT\": {\"REGEX\":\"[abcdABCD]{1}\\/.+\\/.+\"}}],\n",
    "]\n",
    "\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Accession\", patterns)\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6b406-792c-4e7b-b51a-b9575d7e4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spacy_matches(doc,nlp,matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6c2fa-51ae-428c-8906-0a6891b33284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_39",
   "language": "python",
   "name": "pytorch_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
